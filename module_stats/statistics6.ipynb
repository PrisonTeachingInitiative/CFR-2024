{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5148-4cac-461b-b145-eb6d10c97820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['xtick.labelsize'] = '16'\n",
    "plt.rcParams['ytick.labelsize'] = '16'\n",
    "plt.rcParams['axes.labelsize'] = '18'\n",
    "plt.rcParams['axes.titlesize'] = '18'\n",
    "\n",
    "nba_team_stats = pd.read_csv('2023-2024_nba_team_stats_per_game.csv')\n",
    "nba_season_stats = pd.read_csv('2023-2024_season_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fff73a-a12c-4aca-a991-02383eb28660",
   "metadata": {},
   "source": [
    "# Bringing it all together\n",
    "\n",
    "Over the last few weeks, we have spent a lot of time learning how to read in datasets, make hypotheses, and test them with the data. Today, we're going to go through and review everything that we have covered, using the NBA 2023-2024 season team stats. I have two dataframes, one of which is a bunch of \"per game\" stats for every team, and another which is the end of the season standings. Let's take a look at these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4a849-979c-40e5-8419-33865d4c6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_team_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f1934-4871-466d-af57-ac4630826326",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_season_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e069f-0393-4dd5-83f7-5b500613eb57",
   "metadata": {},
   "source": [
    "At the end of the day, wins are the most important stat that we care about--we want the fans to get to see their team winning, and we're going to investigate how different team stats correlated with wins. But the stats we care about are in one dataframe, and the wins are in another dataframe. In order to compare these, we need to combine these data products. The way that we can do this is with a function in pandas called \"merge\". To merge two dataframes, you give the function the two data frames you care about and tell it which column you would like it to combine on. In this case, we want to match on the \"Team\" column. Let's see below how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c18d5-2a8f-42cc-8e83-d316a96e7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_all = pd.merge(nba_team_stats, nba_season_stats, on='Team')\n",
    "\n",
    "nba_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eab286-2bdd-4f64-a1ae-e34329779cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_all.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28e13b-5ffd-4e34-bc0b-025f56075b4e",
   "metadata": {},
   "source": [
    "Now, we have a dataframe that contains a ton of info about all the team stats per game. Let's ask the question: which stat is the most correlated with winning, and which is the least? To do this, let's use the scipy \"linregress\" function. First, before we systematically test this for everything, do we have a guess for what the answer is? Let's test that below to remind ourselves how to measure the correlation coefficient and the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed846c-dfcc-4cca-b7a2-b2d3e6efa412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "column_to_test = 'PTS'\n",
    "\n",
    "fit = linregress(nba_all[column_to_test], nba_all['W'])\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7de753-1b39-4012-b315-5b222d2a96ce",
   "metadata": {},
   "source": [
    "And now, let's plot this, along with the best fitting line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626c579-a2ba-4e5d-bd2d-d202465cb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = fit.slope\n",
    "intercept = fit.intercept\n",
    "\n",
    "x_arr = np.linspace(np.min(nba_all[column_to_test]), np.max(nba_all[column_to_test]), 100)\n",
    "wins_arr = slope * x_arr + intercept\n",
    "\n",
    "plt.plot(nba_all[column_to_test], nba_all['W'], '.')\n",
    "plt.plot(x_arr, wins_arr)\n",
    "plt.xlabel(column_to_test)\n",
    "plt.ylabel('Wins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31849ffe-6e1d-4403-a3e3-7ff1ea6175cb",
   "metadata": {},
   "source": [
    "Our \"fit\" object also contains the spearman r value, which is our best measure of how correlated two variables are. Let's measure that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc38cc7-c941-4e7d-9208-b243a0f70184",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvalue = fit.rvalue\n",
    "\n",
    "print('Spearman r:', rvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be34b87-a283-4230-89fd-db779be22a57",
   "metadata": {},
   "source": [
    "But how can we find out if this is the strongest correlation that exists in our data? We could go through individually and check every single column, but that would be really slow. We can instead employ a loop. Let's take a look at the full list of columns that we want to test. What we can do is do a \"for\" loop where we loop through each of those columns, and do whatever we want to that value. For a quick example, let's loop through and print the average value of every column we care about, in addition to the standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338343b4-34ca-41c2-81c5-b193899d0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_test = ['FG', 'FGA', 'FG%', '3P', '3PA', '3P%',\n",
    "                   '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST',\n",
    "                   'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "\n",
    "for column in columns_to_test:\n",
    "    print(column, np.mean(nba_all[column]), np.std(nba_all[column]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa23244-632a-4bb7-9c21-deacdc467aac",
   "metadata": {},
   "source": [
    "Let's try this again but make it a bit cleaner--to do this, we can use the python \"round\" function to only get a few significant digits for each of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe14c0-b1b2-4b30-9518-93910d75997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_test:\n",
    "    print(column, round(np.mean(nba_all[column]),2), round(np.std(nba_all[column]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70a0c7-7283-4d46-9a5f-9e66589856c0",
   "metadata": {},
   "source": [
    "Looping through data is one of the easiest ways to make measurements for a bunch of different variables that you care about. We can do this again, where this time, we measure the spearman r value for every single statistic that we want to compare to wins. We can even go a step further. Let's loop through, plot every single correlation (with a best fitting line), and save the best fitting r value for every single value. If we want to save values from a loop, a good way to do this is to \"append\" those values to a list every time we move through the loop. We can see how that works below as we loop through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6d8ad-f42f-48ec-ac99-c5ee03e01c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list = []\n",
    "\n",
    "for column in columns_to_test:\n",
    "\n",
    "    fit = linregress(nba_all[column], nba_all['W'])\n",
    "    slope = fit.slope\n",
    "    intercept = fit.intercept\n",
    "    rvalue = fit.rvalue\n",
    "\n",
    "    #append the spearman r value to the list we've set up\n",
    "    r_list.append(rvalue)\n",
    "    \n",
    "    x_arr = np.linspace(np.min(nba_all[column]), np.max(nba_all[column]), 100)\n",
    "    wins_arr = slope * x_arr + intercept\n",
    "\n",
    "    plt.plot(nba_all[column], nba_all['W'], '.')\n",
    "    plt.plot(x_arr, wins_arr)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Wins')\n",
    "    plt.show()\n",
    "\n",
    "#make r_list an array so it's easier to manipulate\n",
    "r_list = np.array(r_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82177d-858d-4091-8f16-d02eabe188e1",
   "metadata": {},
   "source": [
    "Now, let's take a look what our new r_list variable looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd7544-ab7a-42dd-ac29-ba2a3cc21882",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272fb4e-22fb-4682-ba93-828b0710eda4",
   "metadata": {},
   "source": [
    "So r_list is an array of all of the spearman r values that measured. This Now, we want to find out which variable has the strongest positive correlation. Let's take a look at the length of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2f1cf-ce04-47ae-9ecd-cfb8cc92772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146de439-b401-4bee-a921-2e080ad1e910",
   "metadata": {},
   "source": [
    "And now let's take a look at the length of the columns that we looped through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945280de-bc74-4049-8985-b79bc869a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns_to_test), columns_to_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3761429-7326-4d68-adc8-e66f3e523299",
   "metadata": {},
   "source": [
    "These have the same length, and they should, because we saved one value of r for every column that we tested. So every value in the r_list corresponds to the r value for the variable that is at the same index position in the columns_to_test list. So if we want to find the variable that is the most strongly correlated with wins, what we want to do is look for the maximum value in r_list. Let's see what that maximum is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae3d7c-29cb-45e6-90db-a0aae4fc4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(r_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f14e4-fe63-4ffb-928c-c4f61a9a04ea",
   "metadata": {},
   "source": [
    "Now we know that there is something in there that is strongly correlated with wins, and we want to find out what it is. To do this, we need to find the \"argmax\" of that variable--the index of the list that corresponds to the maximum value. We can do that with the np.argmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23b2c9-7980-4997-947c-5148cbf57fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(r_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ca843-4068-4eb8-a7d6-5f970ac4c972",
   "metadata": {},
   "source": [
    "What that tells us is that the \"5th\" element of the list corresponds to the highest value. Because of the way arrays and lists work in python, we can easily see what that value is like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c5e28-067c-4936-9aa3-ba7b210ffed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_test[np.argmax(r_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d4fa0-230c-4df2-a554-b55dfcc03af5",
   "metadata": {},
   "source": [
    "Interesting! So we can actually see that the stat that is the most strongly correlated with winning isn't points/game, it's actually 3 point percentage! Let's take a look again at that correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ec27c-60e3-4f8b-bb58-79c2ee0c4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_max = columns_to_test[np.argmax(r_list)]\n",
    "\n",
    "fit = linregress(nba_all[column_max], nba_all['W'])\n",
    "slope = fit.slope\n",
    "intercept = fit.intercept\n",
    "rvalue = fit.rvalue\n",
    "\n",
    "x_arr = np.linspace(np.min(nba_all[column_max]), np.max(nba_all[column_max]), 100)\n",
    "wins_arr = slope * x_arr + intercept\n",
    "\n",
    "plt.plot(nba_all[column_max], nba_all['W'], '.')\n",
    "plt.plot(x_arr, wins_arr)\n",
    "plt.xlabel(column_max)\n",
    "plt.ylabel('Wins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc445e17-88ac-4efb-8d4b-578dcc4a8658",
   "metadata": {},
   "source": [
    "It's interesting to see that even though there's only a small range in the total percentages teams shoot (the worst teams shoot 34%, the best teams shoot 39%), the correlation is so strong. Let's take a look at the slope and interpret it. How can we interpret this number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7b709-701b-49b5-b5d3-8967f62367a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20643657-ca7f-427c-af6d-a7c1acca2dda",
   "metadata": {},
   "source": [
    "The slope has units of \"wins per 3P%\", so if we want to know how many wins shooting 1% better at the 3 point line corresponds to, we can multiply our slope by the value we want to see. Let's check to see how much of an increase in wins 1% at the free throw line corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cbc3fb-5665-486e-b840-f403538ea111",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01 * slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21194f-50ea-4ec4-8db9-1cd9d05af623",
   "metadata": {},
   "source": [
    "So shooting 1% better at the line corresponds to winning 8 more games in a season! That's a huge increase for what seems like such a small number, but when you're shooting 30-40 three point shots every game, that 1% difference corresponds to a lot of points on average!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3bba2-6bee-4288-b9d4-e4bb83e7ee39",
   "metadata": {},
   "source": [
    "# Activity: find out what the strongest *negative* correlation in the catalog is. Also, find out which statistic is the least correlated with wins.\n",
    "\n",
    "After you find these, plot the relations.\n",
    "\n",
    "- Hint: the opposite of \"argmax\" is \"argmin\"\n",
    "\n",
    "- Hint: to find the least correlated variable, you want to find to find the value that is the closest to 0, regardless of sign. There are a few ways that you can do this, but one way is to think about the statistic we measured that is very closely related to the rvalue as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c6418-ccd9-4569-8847-05386d0147a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef9bbd-5b20-4ade-99e5-ea87058ad045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0d6aa-5f2d-4e3c-b285-3620bfb69d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397bd30-cd34-464b-ac99-bc183d087f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b5e6b-9212-42da-b061-33cbda29c8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9940173-405a-46e4-8033-7ab5aa817d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "385049f2-4f11-48ea-b4dd-f06746ecc07a",
   "metadata": {},
   "source": [
    "# Some other activities if you have time:\n",
    "\n",
    "- Which team had the largest \"point differential\" (points/game - points against/game). Is this the same team that had the most wins? Is this new stat more strongly correlated with wins than 3 point percentage?\n",
    "\n",
    "- How do \"volume\" stats like the number of 3 points attempted correlated with the 3 point percentage? Is that correlation the same as for 2 point shots? What about the number of total shot attempts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452acf07-3906-498c-83a5-d6c35a051e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c484a-ab25-42ab-a4d1-50c73a4bd92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7daf9f-9ab3-41cb-ab27-ea5b116a9acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
